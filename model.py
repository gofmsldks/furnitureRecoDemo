import cv2
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import io
import base64
import json
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
#import os
#import httpx
#from langchain.chains import RetrievalQA
#from langchain_openai import OpenAI
from langchain_openai import ChatOpenAI
#from langchain.prompts import PromptTemplate
#from langchain.indexes import VectorstoreIndexCreator
from langchain_community.vectorstores import FAISS
#from langchain.text_splitter import CharacterTextSplitter
from langchain.docstore.document import Document
from langchain.schema import HumanMessage
from langchain.schema import SystemMessage
from langchain_openai import OpenAIEmbeddings
from dotenv import load_dotenv
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter
#from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_community.vectorstores.utils import DistanceStrategy

#from langchain.chains import LLMChain

#from json import dumps
#conda install nomkl

load_dotenv()
#os.environ["OPENAI_API_KEY"] = "OPENAI API KEY ì…ë ¥"

# OpenAI API í‚¤ ì„¤ì •
#OPENAI_API_KEY = "your_openai_api_key"




# **** RAG ëŒ€ìƒ ë¬¸ì„œ ë¡œë“œ í•˜ëŠ” ë¶€ë¶„(ë”°ë¡œ ëª¨ë“ˆë¡œ ë§Œë“¤ ì˜ˆì •)****

# LangChainì„ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”© ìƒì„± model="text-embedding-3-large"
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

# ìƒ‰ìƒ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
color_database = {}
with open('./color_data.txt', 'r',  encoding='UTF8') as file:
    for line in file:
        if ':' in line:
            key, value = line.split(':', 1)
            key = key.strip()
            value = value.strip('()\n').split(',')
            value = tuple(map(int, value))
            color_database[key] = value
# ìƒ‰ìƒ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•œ RAG ì„¤ì •
color_info_documents = [
    Document(page_content=f"The color {color} has the RGB values {rgb}.") for color, rgb in color_database.items()
]
print(color_info_documents)
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0, separator="\n")
color_info_docs = text_splitter.split_documents(color_info_documents)
color_info_db = FAISS.from_documents(color_info_docs, embeddings)
color_retriever = color_info_db.as_retriever()
#print(color_database)



# ê°€êµ¬ ë°ì´í„°ë² ì´ìŠ¤

loader = TextLoader("./new_data.txt",  encoding='UTF8')
documents = loader.load()
# CharacterTextSplitterë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ë¶„í• í•©ë‹ˆë‹¤.
text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=50)
# ë¶„í• ëœ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
docs1 = text_splitter.split_documents(documents)
# ê°€êµ¬ ì •ë³´ ì„ë² ë”©
furniture_embeddings_db = FAISS.from_documents(docs1, embeddings)
furniture_retriever = furniture_embeddings_db.as_retriever(search_type="similarity")


# ê°€êµ¬ ìº¡ì…˜ ë°ì´í„°ë² ì´ìŠ¤

loader = TextLoader("./data.txt",  encoding='UTF8')
documents = loader.load()
# CharacterTextSplitterë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ë¶„í• í•©ë‹ˆë‹¤.
text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=0, separator="\n")

# ë¶„í• ëœ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
docs = text_splitter.split_documents(documents)

# ê°€êµ¬ ìº¡ì…˜ ì •ë³´ ì„ë² ë”©
caption_embeddings_db = FAISS.from_documents(docs, embeddings, distance_strategy=DistanceStrategy.COSINE)

'''
# ./furnitrueCaptions.txt íŒŒì¼ ë‚´ìš©ì„ ì½ì–´ì„œ file ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤.
with open("./furnitrueCaptions.txt") as f:
    furniture_captions = f.read()  # íŒŒì¼ì˜ ë‚´ìš©ì„ ì½ì–´ì„œ file ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤.
    print(furniture_captions)
'''

# **** RAG ëŒ€ìƒ ë¬¸ì„œ ë¡œë“œ í•˜ëŠ” ë¶€ë¶„ ë ****




# ì´ë¯¸ì§€ ì²˜ë¦¬ í•¨ìˆ˜
def image_processing(image):
    # OpenCVë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ RGBë¡œ ë³€í™˜
    image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
    image = image.reshape((image.shape[0] * image.shape[1], 3))

    # K-means í´ëŸ¬ìŠ¤í„°ë§ì„ ì‚¬ìš©í•˜ì—¬ ì£¼ìš” ìƒ‰ìƒ ì¶”ì¶œ
    num_clusters = 5  # ì¶”ì¶œí•  ìƒ‰ìƒì˜ ìˆ˜
    clt = cv2.kmeans(np.float32(image), num_clusters, None,
                     (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2),
                     10, cv2.KMEANS_RANDOM_CENTERS)[2]

    # ì£¼ìš” ìƒ‰ìƒì„ ì¶”ì¶œí•œ í›„ ê°€ì¥ ë¹ˆë„ ë†’ì€ ìƒ‰ìƒ ì„ íƒ
    unique, counts = np.unique(clt, axis=0, return_counts=True)
    dominant_color = unique[np.argmax(counts)]

    # RGB ìƒ‰ìƒ ë°˜í™˜
    return tuple(dominant_color)


# ìƒ‰ìƒ ì¶”ì²œ í•¨ìˆ˜ (RAG ê¸°ëŠ¥ í¬í•¨) - ì‚¬ìš©ì ì‚¬ì§„ì—ì„œ ì¶”ì¶œí•œ ìƒ‰ê¹”ì¤‘ ë¦¬ë°”íŠ¸ ê°€êµ¬ ìƒ‰ê¹”ê³¼ ê°€ì¥ ë¹„ìŠ·í•œ ìƒ‰ ê³¨ë¼ë‚´ê¸°
def get_color_recommendations(dominant_color):
    closest_color_name = min(color_database,
                             key=lambda k: np.linalg.norm(np.array(color_database[k]) - np.array(dominant_color)))
    return closest_color_name


# LLMì— ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ì „ë‹¬í•˜ì—¬ ì¶”ì²œ ê²°ê³¼ ìƒì„±
def recommendation_engine_with_image(image_base64):
    try:
        # Base64 ë¬¸ìì—´ì—ì„œ í—¤ë”ê°€ ìˆì„ ê²½ìš° ì œê±°
        if "," in image_base64:
            image_base64 = image_base64.split(",")[1]  # í—¤ë” ì œê±°

        # Base64 ë””ì½”ë”©
        image_data = base64.b64decode(image_base64)

        # ë””ì½”ë”©ëœ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë°”ì´íŠ¸ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì´ë¯¸ì§€ ë¡œë“œ
        image = Image.open(io.BytesIO(image_data))

        # OpenCVë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ RGBë¡œ ë³€í™˜
        dominant_color = image_processing(image)

        # ì¶”ì¶œëœ ì£¼ìš” ìƒ‰ìƒê³¼ ê°€ì¥ ë¹„ìŠ·í•œ ìƒ‰ìƒ ì°¾ê¸°
        closest_color_name = get_color_recommendations(dominant_color)

        return image, closest_color_name
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None

# JSON í¬ë§·íŒ… í•¨ìˆ˜
def format_documents(docs):
    formatted_docs = []
    for doc in docs:
        try:
            # page_contentë¥¼ JSONìœ¼ë¡œ ë¡œë“œ
            content_json = json.loads(doc.page_content)
            # ë³´ê¸° ì¢‹ê²Œ JSON ë¬¸ìì—´ë¡œ ë³€í™˜
            formatted_docs.append(json.dumps(content_json, indent=4, ensure_ascii=False))
        except json.JSONDecodeError:
            # JSONì´ ì•„ë‹Œ ê²½ìš° ê·¸ëŒ€ë¡œ ì¶”ê°€
            formatted_docs.append(doc.page_content)
    return formatted_docs

def vision_chain(inputs):
    try:
        image_base64, question = str(inputs["image"]), str(inputs["question"])
        image_data, closest_color_name = recommendation_engine_with_image(image_base64)
        # retrieverì—ì„œ ë°ì´í„°ë¥¼ ê²€ìƒ‰
        context_docs = furniture_retriever.invoke(question)
        context2_docs = color_retriever.invoke(closest_color_name)

        # í¬ë§·íŒ…ëœ ë°ì´í„° ìƒì„±
        context = format_documents(context_docs)
        context2 = format_documents(context2_docs)

        print('*********')
        print(context)
        print(context2)
        # LangChainì„ ì‚¬ìš©í•˜ì—¬ LLM í˜¸ì¶œ
        llm = ChatOpenAI(model="gpt-4o")

        # í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ì¤€ë¹„
        system_message = SystemMessage(
            content=[
'''
## ì—­í•  ë° ëª©í‘œ  
ë‹¹ì‹ ì€ í˜„ëŒ€ë¦¬ë°”íŠ¸ì˜ AI ê°€êµ¬ ì¶”ì²œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.  
ì‚¬ìš©ìê°€ ì œê³µí•œ **ì´ë¯¸ì§€, ìƒ‰ìƒ, ì§ˆë¬¸(Context, Question)**ì„ ë¶„ì„í•˜ì—¬ **ê°€ì¥ ì ì ˆí•œ ê°€êµ¬ì™€ ì¸í…Œë¦¬ì–´ ìŠ¤íƒ€ì¼ì„ ì¶”ì²œ**í•´ì•¼ í•©ë‹ˆë‹¤.  

---

## ğŸ”¹ **ì‘ì—… ë°©ì‹**
1. **ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì£¼ìš” ìƒ‰ìƒì„ ì¶”ì¶œí•©ë‹ˆë‹¤.**  
   - ì´ë¯¸ì§€ ì¸ì‹ì„ ëª»í•˜ê±°ë‚˜ ì—†ì„ ê²½ìš°, ìƒ‰ìƒ ë¶„ì„ì„ ìƒëµí•˜ê³  `Question`ê³¼ `Context`ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.  
2. **Contextì—ì„œ ì œê³µëœ ê°€êµ¬ ë°ì´í„°ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ìš”ì²­ê³¼ ì¼ì¹˜í•˜ëŠ” ê°€êµ¬ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.**  
   - ContextëŠ” JSON ë°ì´í„°ë¡œ ì œê³µë˜ë©°, ê° ê°€êµ¬ì˜ **ì´ë¦„(`mdl_nm`), ìƒ‰ìƒ(`mdl_color`), ì„¤ëª…(`mdl_detail`), ê°€ê²©(`cost`), ìƒí’ˆ ì½”ë“œ(`mdl_cd`)** ì •ë³´ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.  
   - ë°˜ë“œì‹œ `Context` ë‚´ì—ì„œ ì¼ì¹˜í•˜ëŠ” ê°€êµ¬ë¥¼ ì°¾ì•„ ì¶”ì²œí•˜ì„¸ìš”.  
   - Contextì— ì ì ˆí•œ ê°€êµ¬ê°€ ì—†ì„ ê²½ìš°, `"ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì¹˜í•˜ëŠ” ê°€êµ¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."`ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.  
3. **ì¶œë ¥ í˜•ì‹ì€ ì±„íŒ… ìŠ¤íƒ€ì¼ë¡œ êµ¬ì„±í•˜ë©°, ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.**  

---

## ğŸ“Œ **ì¶œë ¥ í˜•ì‹**
(ì•„ë˜ ì˜ˆì‹œë¥¼ ê·¸ëŒ€ë¡œ ë”°ë¼ì£¼ì„¸ìš”.)

**ğŸ“¸ ì‚¬ì§„ ë¶„ì„ ê²°ê³¼**  
- ì¸í…Œë¦¬ì–´ ë¶„ìœ„ê¸°: {ì´ë¯¸ì§€ì—ì„œ ë¶„ì„ëœ ë¶„ìœ„ê¸°}  
- ì£¼ìš” ìƒ‰ìƒ: {ì´ë¯¸ì§€ì—ì„œ ì¶”ì¶œí•œ ìƒ‰ìƒ}  
- ì¶”ì²œ ìƒ‰ìƒ: {Contextì—ì„œ ê°€ì¥ ì˜ ì–´ìš¸ë¦¬ëŠ” ìƒ‰ìƒ}  
- ì¶”ì²œ ì´ìœ : {í•´ë‹¹ ìƒ‰ìƒì´ ì–´ìš¸ë¦¬ëŠ” ì´ìœ }  

---

**ğŸ›‹ï¸ ì¶”ì²œ ê°€êµ¬ ë¦¬ìŠ¤íŠ¸**  
1. **ê°€êµ¬ëª…:** {mdl_nm}  
   **ìƒ‰ìƒ:** {mdl_color}  
   **ì„¤ëª…:** {mdl_detail}  
   **ê°€ê²©:** {cost} ì›  
   **ìƒí’ˆ:** [ìƒì„¸ ë³´ê¸°]({mdl_cd})  

2. **ê°€êµ¬ëª…:** {mdl_nm}  
   **ìƒ‰ìƒ:** {mdl_color}  
   **ì„¤ëª…:** {mdl_detail}  
   **ê°€ê²©:** {cost} ì›  
   **ìƒí’ˆ:** [ìƒì„¸ ë³´ê¸°]({mdl_cd})  

(ìµœëŒ€ 5ê°œê¹Œì§€ ì¶œë ¥)  

---

**ğŸ¨ ì¸í…Œë¦¬ì–´ ë°©í–¥ì„±**  
1. **ì£¼ìš” ìƒ‰ìƒ:** {ì¶”ì²œëœ ì£¼ìš” ìƒ‰ìƒ}  
2. **ìŠ¤íƒ€ì¼:** {ì¶”ì²œ ì¸í…Œë¦¬ì–´ ìŠ¤íƒ€ì¼}  
3. **ì¶”ì²œ ì´ìœ :** {ì™œ ì´ ìŠ¤íƒ€ì¼ì´ ì í•©í•œì§€ ì„¤ëª…}  

---

**â­ ìµœì¢… ê¶í•© ì ìˆ˜**  
ê° ê°€êµ¬ì™€ ì‚¬ìš©ìì˜ ì·¨í–¥ì— ëŒ€í•œ ê¶í•© ì ìˆ˜ë¥¼ â­â­â­â­â­ (5ì  ë§Œì )ìœ¼ë¡œ í‘œì‹œí•˜ì„¸ìš”.  
ì˜ˆ:  
- `ì¹¨ëŒ€ í”„ë ˆì„`: â­â­â­â­â˜† (4/5)  
- `ì†ŒíŒŒ`: â­â­â­â­â­ (5/5)  
- `ì‹íƒ`: â­â­â­â˜†â˜† (3/5)  

> **ğŸ’¡ í•œ ì¤„ ì´í‰:** `{ì¶”ì²œëœ ì¸í…Œë¦¬ì–´ ìŠ¤íƒ€ì¼ì— ëŒ€í•œ ìš”ì•½}` âœ¨  

---

## âš ï¸ **ì£¼ì˜ ì‚¬í•­**
1. **ë°˜ë“œì‹œ Context ë‚´ ê°€êµ¬ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ì²œí•˜ì„¸ìš”.**  
2. **Contextì—ì„œ ë§¤ì¹­ë˜ëŠ” ê°€êµ¬ê°€ ì—†ìœ¼ë©´, "ì¼ì¹˜í•˜ëŠ” ê°€êµ¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•˜ì„¸ìš”.**  
3. **ì¶œë ¥ í˜•ì‹ê³¼ êµ¬ì¡°ë¥¼ ìœ ì§€í•´ì£¼ì„¸ìš”.**  
4. **í•œê¸€ë¡œ ë‹µë³€í•˜ê³ , ê°€ë…ì„±ì„ ê³ ë ¤í•´ ì •ë¦¬ëœ ë¬¸ì¥ì„ ì‚¬ìš©í•˜ì„¸ìš”.**  
5. **ì´ë¯¸ì§€ë¥¼ ì¸ì‹ ëª»í•œë‹¤ë©´ ê°€êµ¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ê³  í•˜ì§€ ë§ê³  Contextì™€ Question ê¸°ì¤€ìœ¼ë¡œ ì¶”ì²œí•´ì£¼ì„¸ìš”**
'''
+ f'#Context: {context}'
            ]
        )

        # ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ base64ë¡œ ì¸ì½”ë”©
        #image_data_base64 = base64.b64encode(image_data).decode("utf-8")
        image_data_base64 = image_base64
        # ë©€í‹°ëª¨ë‹¬ ë©”ì‹œì§€ ìƒì„±
        human_message = HumanMessage(
            content=[
                {
                    "type": "text",
                    "text": f"ì‚¬ì§„ì˜ ì£¼ìš” ìƒ‰ê¹”ì€ {context2}, \n ì„ í˜¸ ìƒ‰ìƒ ë° ìŠ¤íƒ€ì¼ ê´€ë ¨ ì‚¬ìš©ì ì§ˆë¬¸ì€ {question}"
                },
                {
                    "type": "image_url",
                    #"image_url": {"url": f"data:image/jpeg;base64,{image_data_base64}"},
                    "image_url": {"url": f"{image_data_base64}"},
                },
            ],
        )
        #prompt = prompt_template.format(closest_color_name=closest_color_name, user_preference=user_preference, context=retriever)
        # RAG ì²´ì¸ ìƒì„±
        #chain = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=vectorstore.as_retriever())

        # í”„ë¡¬í”„íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ í•¨ê»˜ ì „ì†¡í•˜ì—¬ ì‘ë‹µ ë°›ê¸°
        response = llm.invoke([system_message, human_message])

        return response.content

    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None


# ìœ ì‚¬ ê°€êµ¬ ì°¾ê¸° í•¨ìˆ˜
def find_similar_furniture(user_input):

    #print(caption_embeddings_db)
    # ìœ ì‚¬ë„ ë¹„êµ
    highest_similarity = 0
    most_similar_image_path = None

    user_input = user_input +'ê²½ë¡œì™€ ì¹´í…Œê³ ë¦¬ ê°€êµ¬ì •ë³´ í•´ì‹œí…Œê·¸ êµ¬ë³„í•´ì„œ ì¶”ì¶œ'
    content_and_similarity_score = caption_embeddings_db.similarity_search_with_score(user_input)
    #print(content_and_similarity_score[0])
    content, similarity_score = content_and_similarity_score[0]
    most_similar_content = content.page_content
    highest_similarity = similarity_score
    #print(most_similar_content, highest_similarity)
    return most_similar_content, highest_similarity
'''
    for i in range(0, len(content_and_similarity_score)):
        content, similarity_score = content_and_similarity_score[i]
        #print(content.page_content, similarity_score)

        if similarity_score > highest_similarity:
            highest_similarity = similarity_score
            most_similar_content = content.page_content
'''



# ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ í•¨ìˆ˜
def chat_interface(image_base64, user_preference):
    #print("ì•ˆë…•í•˜ì„¸ìš”! ì¸í…Œë¦¬ì–´ ë° ê°€êµ¬ ìƒ‰ìƒ ì¶”ì²œ ì±—ë´‡ì…ë‹ˆë‹¤.")

    #mode = input("ì¶”ì²œì„ ë°›ê³  ì‹¶ì€ ìŠ¤íƒ€ì¼ì˜ ì‚¬ì§„ì„ ì…ë ¥í•˜ë ¤ë©´ 1ì„, ë¹„ìŠ·í•œ ê°€êµ¬ë¥¼ ì°¾ê³  ì‹¶ìœ¼ë©´ 2ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”: ")
    mode = '1'
    if mode == '1':
        # ìŠ¤íƒ€ì¼ ì¶”ì²œì„ ë°›ê³  ì‹¶ì€ ê²½ìš°
        #p_number = input("ì¶”ì²œì„ ë°›ê³  ì‹¶ì€ ì¸í…Œë¦¬ì–´ ë˜ëŠ” ê°€êµ¬ì˜ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”: ")
        #image_path = f'./style{p_number}.jpeg'
        #user_preference = input("ì„ í˜¸í•˜ëŠ” ìƒ‰ìƒ ë˜ëŠ” ìŠ¤íƒ€ì¼ì„ ì…ë ¥í•´ì£¼ì„¸ìš”: ")
        #print("\nì‚¬ìš©ì ì´ë¯¸ì§€\n")
        #img = Image.open(image_path)
        # ì´ë¯¸ì§€ í‘œì‹œ
        #plt.imshow(img)
        #plt.axis('off')  # ì¶• ì—†ì• ê¸°
        #plt.show()
        #print("*****ì™„ë£Œ*****\n")

        #image_data = base64.b64decode(image_base64)

        try:
            # ìƒ‰ìƒ ë° ì¸í…Œë¦¬ì–´ êµ¬ì„± ë°©ì‹ ì¶”ì²œ
            final_chain = (
                    vision_chain | StrOutputParser()
            )

            # Vision Chainì— ì´ë¯¸ì§€ ë°ì´í„°ì™€ ì§ˆë¬¸ ì „ë‹¬
            res = final_chain.invoke({"image": image_base64
                                    , "question": user_preference
                                      })
            return res
        except Exception as e:
            print(f"Error in vision_chain: {e}")
            raise
        # ì¶”ì²œ ê²°ê³¼ ì¶œë ¥
        #print(f"### ì¶”ì²œ ê²°ê³¼: {res}")

    elif mode == '2':
        # ë¹„ìŠ·í•œ ê°€êµ¬ë¥¼ ì°¾ê³  ì‹¶ì€ ê²½ìš°
        user_input = input("ì°¾ê³  ì‹¶ì€ ê°€êµ¬ì˜ ìŠ¤íƒ€ì¼, ë¶„ìœ„ê¸°, ì¹´í…Œê³ ë¦¬, ëª¨ì–‘ ë“±ì„ ì…ë ¥í•´ì£¼ì„¸ìš”: ")

        # ë¹„ìŠ·í•œ ê°€êµ¬ ì°¾ê¸°
        most_similar_contents, score = find_similar_furniture(user_input)
        print((most_similar_contents))
        match_score = int(100*(1 - score))
        idx=1
        print("\n###ìœ ì‚¬í•œ ê°€êµ¬ ë¦¬ìŠ¤íŠ¸###")
        for sc in list(most_similar_contents.split('\n')):
            for s in list(sc.split(r'\n')):
                print(f"## ê°€ì¥ ìœ ì‚¬í•œ ê°€êµ¬ {idx}ì˜ {s} ##\n")
            idx += 1
            print('\n')
        print(f"--------ê¶í•©ì ìˆ˜: {match_score}ì ##--------")





# ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰ í•¨ìˆ˜
#chat_interface()
